{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac41ae1-fe8e-4119-8ede-c54a8e40da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openCV.python in c:\\users\\aparna iyer\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\aparna iyer\\anaconda3\\lib\\site-packages (from openCV.python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install openCV.python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9da9313-e421-43c8-b63d-2430a0e18658",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Name: Aparna Iyer\n",
    "###PRN: 22070126017\n",
    "###Batch: AI-ML A1, 2022-2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902d766-7e8a-4e5e-818d-826f39980610",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Experiment 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25129e-8e3d-41d9-b7b3-2db67a52f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Title: Discuss about recognizing objects in consumer images, analyzing human activity in video using tools / platforms.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6c4b9-b315-4051-a1e4-368c748543a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Aim:\n",
    "To develop a Python application for object recognition in images and human activity analysis in videos by:\n",
    "\n",
    "1. Accessing a camera using OpenCV.\n",
    "2. Capturing and saving video.\n",
    "3. Performing frame-wise operations like object detection using Haar-Cascade and image processing techniques such as blurring, negatives, and enhancement.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805887af-3a64-4d22-90a0-52c2ab545612",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Objectives:\n",
    "\n",
    "1) Access the camera integrated with Desktop/Laptop using OpenCV in Python.\n",
    "2) Capture the video and store the same.\n",
    "3) Perform different operations frame-wise on captured images/ video by using Haar-Cascade.\n",
    "4) Operations includes blurring, negative, enhancement etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b9ca7-cd2d-425b-826c-519e12dff459",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Theory:\n",
    "\n",
    "Camera Basics\n",
    "A camera captures light and converts it into images or videos through:\n",
    "\n",
    "Lens: Focuses light.\n",
    "Sensor: Converts light into signals (e.g., CMOS, CCD).\n",
    "Shutter & Aperture: Control light entry.\n",
    "\n",
    "OpenCV enables real-time camera interaction to capture and process video frames. Videos are recorded as frame sequences at a specific frame rate (e.g., 30 fps). Key functions include cv2.VideoCapture() for camera access and frame manipulation for storage or processing.\n",
    "\n",
    "Haar-Cascade:It is a machine learning-based object detection method. It uses pre-trained classifiers to detect objects (e.g., faces, eyes) in images by scanning for specific features. It's efficient and widely used for real-time applications.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43999057-1ba3-4d77-8016-e443ff50d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #Computer Vision Library, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f880a96-ccac-4359-b213-91437be4fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the default camera\n",
    "\n",
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8c4c9ac-a465-4efa-b080-a85fa8410fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the default frame width and height\n",
    "\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH)) #Set frame width to default width of camera\n",
    "\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT)) #Set frame height to default height of camera\n",
    "\n",
    "#Define the codec and create VideoWriter object\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_sobel = cv2.VideoWriter('Downloads\\output_sobel.mp4',fourcc,20.0,(frame_width,frame_height))\n",
    "out_canny = cv2.VideoWriter('Downloads\\output_canny.mp4',fourcc,20.0,(frame_width,frame_height))\n",
    "out_negative = cv2.VideoWriter('Downloads\\output_negative.mp4',fourcc,20.0,(frame_width,frame_height))\n",
    "out_blurred = cv2.VideoWriter('Downloads\\output_blurred.mp4',fourcc,20.0,(frame_width,frame_height))\n",
    "out_greyscale = cv2.VideoWriter('Downloads\\output_greyscale.mp4',fourcc,20.0,(frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a008a5-7d10-4138-a52e-83d45c3369c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Canny Edge Detection\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    out_canny.write(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "    cv2.imshow('Canny Edge Detection', edges)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "out_canny.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcaf7ca8-7fff-4527-bf74-0e8f71f5d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Sobel Edge Detection\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    sobel_x = cv2.convertScaleAbs(sobel_x)\n",
    "    sobel_y = cv2.convertScaleAbs(sobel_y)\n",
    "    sobel_combined = cv2.addWeighted(sobel_x, 0.5, sobel_y, 0.5, 0)\n",
    "\n",
    "    out_sobel.write(cv2.cvtColor(sobel_combined, cv2.COLOR_GRAY2BGR))\n",
    "    cv2.imshow('Sobel Edge Detection', sobel_combined)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "out_sobel.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf5f9f5-f03a-4d88-ac6a-21aa6af0163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Video Negative\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    neg = 255 - frame\n",
    "    out_negative.write(neg)\n",
    "    cv2.imshow('Negative Frame', neg)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "out_negative.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d1cff33-19a2-441b-a660-f036f5e35747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Blurring\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    blurred = cv2.GaussianBlur(frame, (15, 15), 0)\n",
    "    out_blurred.write(blurred)\n",
    "    cv2.imshow('Blurred Frame', blurred)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "out_blurred.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "038bc397-e279-4b10-be1b-51bd2ba7964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Grayscale Video\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    out_greyscale.write(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR))\n",
    "    cv2.imshow('Grayscale Frame', gray)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "out_greyscale.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb535af5-0c76-4499-88aa-b739dd5ef6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Conclusion: \n",
    "\n",
    "The experiment utilizes various image enhancement techniques which have the following real-world applications:\n",
    "\n",
    "1. Canny Edge Detection:\n",
    "\n",
    "a. Detecting lanes in autonomous driving systems.\n",
    "b. Identifying tumor boundaries in medical imaging.\n",
    "c. Enhancing features in facial recognition.\n",
    "\n",
    "2. Sobel Edge Detection:\n",
    "\n",
    "a. Highlighting edges in industrial quality control (e.g., detecting defects in products).\n",
    "b. Assisting in topographical map analysis and satellite image processing.\n",
    "c. Enhancing object contours for character recognition in OCR systems.\n",
    "\n",
    "3. Negative:\n",
    "\n",
    "a. Improving contrast in X-rays and MRI scans for medical diagnosis.\n",
    "b. Emphasizing details in astronomical imaging.\n",
    "c. Creating artistic effects in photography and graphic design.\n",
    "\n",
    "4. Blurring:\n",
    "\n",
    "a. Reducing image noise in preprocessing pipelines for object detection.\n",
    "b. Creating background effects in portrait photography.\n",
    "c. Smoothing textures for better segmentation in computer vision tasks like skin lesion analysis.\n",
    "\n",
    "5. Grayscale Conversion:\n",
    "\n",
    "a. Reducing computational complexity for image processing tasks.\n",
    "b. Enhancing the efficiency of object detection and recognition systems.\n",
    "Converting multi-channel images into single-channel for applications like thresholding and edge detection.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
